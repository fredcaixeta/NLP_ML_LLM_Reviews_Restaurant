{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311919ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos na coluna 'comment' antes da limpeza no treino: 0\n",
      "Shape do dataframe de treino após remover nulos: (651, 1)\n",
      "\n",
      "DataFrame de Treino com Comentários Limpos (Primeiras Linhas):\n",
      "                                             comment  \\\n",
      "0  judging from previous posts this used to be a ...   \n",
      "1  we , there were four of us , arrived at noon -...   \n",
      "2  they never brought us complimentary noodles , ...   \n",
      "3  the food was lousy - too sweet or too salty an...   \n",
      "4  after all that , they complained to me about t...   \n",
      "\n",
      "                                     comment_cleaned  \n",
      "0  judging from previous posts this used to be a ...  \n",
      "1  we , there were four of us , arrived at noon -...  \n",
      "2  they never brought us complimentary noodles , ...  \n",
      "3  the food was lousy - too sweet or too salty an...  \n",
      "4  after all that , they complained to me about t...  \n",
      "\n",
      "Valores nulos na coluna 'comment' antes da limpeza na validação: 0\n",
      "Shape do dataframe de validação após remover nulos: (199, 1)\n",
      "\n",
      "DataFrame de Validação com Comentários Limpos (Primeiras Linhas):\n",
      "                                                 comment  \\\n",
      "19784                        The pizza was really good .   \n",
      "19788  Knowledge of the chef and the waitress are bel...   \n",
      "19792                               The service was ok .   \n",
      "19796  I 'm happy to have Nosh in the neighborhood an...   \n",
      "19800                    Indoor was very cozy and cute .   \n",
      "\n",
      "                                         comment_cleaned  \n",
      "19784                        the pizza was really good .  \n",
      "19788  knowledge of the chef and the waitress are bel...  \n",
      "19792                               the service was ok .  \n",
      "19796  i 'm happy to have nosh in the neighborhood an...  \n",
      "19800                    indoor was very cozy and cute .  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# # Opcional: para remover stopwords\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords') # Execute se necessário\n",
    "# stop_words = set(stopwords.words('english')) # Defina a lista de stopwords (ajuste o idioma se necessário)\n",
    "\n",
    "# Função para limpar o texto do comentário\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Converter para minúsculas\n",
    "        text = text.lower()\n",
    "        # Remover pontuação, números e caracteres especiais (mantém apenas letras e espaços)\n",
    "        #text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        # Opcional: Remover stopwords\n",
    "        #text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "        # Substituir múltiplos espaços por um único espaço e remover espaços no início/fim\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    return \"\" # Retorna string vazia ou algum marcador para entradas não-string/NaN\n",
    "\n",
    "# --- Processar dataset_train.csv ---\n",
    "train_file_path = 'dataset_train.csv'\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(train_file_path, sep='|')\n",
    "\n",
    "    # Verificar o nome da coluna de comentários. Baseado nos passos anteriores, assumimos que seja 'comment'.\n",
    "    # Se for outro nome, ajuste aqui:\n",
    "    comment_column_name = 'comment' # <--- Verifique o nome real da coluna no seu CSV\n",
    "\n",
    "    # Verificar se a coluna existe\n",
    "    if comment_column_name not in df_train.columns:\n",
    "        raise ValueError(f\"Coluna '{comment_column_name}' não encontrada em {train_file_path}\")\n",
    "\n",
    "    # Tratar possíveis valores nulos na coluna de comentários ANTES de limpar\n",
    "    # É crucial que a limpeza receba strings. Remover ou preencher NaNs é importante.\n",
    "    print(f\"Valores nulos na coluna '{comment_column_name}' antes da limpeza no treino: {df_train[comment_column_name].isnull().sum()}\")\n",
    "    df_train.dropna(subset=[comment_column_name], inplace=True) # Remover linhas com comentários nulos\n",
    "    print(f\"Shape do dataframe de treino após remover nulos: {df_train.shape}\")\n",
    "\n",
    "\n",
    "    # Aplicar a função de limpeza à coluna de comentários\n",
    "    # Vamos criar uma nova coluna para manter o texto original, se desejar\n",
    "    df_train['comment_cleaned'] = df_train[comment_column_name].apply(clean_text)\n",
    "\n",
    "    print(\"\\nDataFrame de Treino com Comentários Limpos (Primeiras Linhas):\")\n",
    "    print(df_train.head())\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo '{train_file_path}' não encontrado.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Erro de validação: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao processar {train_file_path}: {e}\")\n",
    "\n",
    "\n",
    "# --- Processar dataset_valid.csv ---\n",
    "valid_file_path = 'dataset_valid.csv'\n",
    "\n",
    "try:\n",
    "    df_valid = pd.read_csv(valid_file_path, sep='|')\n",
    "\n",
    "    # Verificar o nome da coluna de comentários no arquivo de validação\n",
    "    # (Assumimos que é o mesmo nome da coluna de treino)\n",
    "    comment_column_name_valid = 'comment' # <--- Verifique se é o mesmo nome no seu CSV de validação\n",
    "\n",
    "    # Verificar se a coluna existe\n",
    "    if comment_column_name_valid not in df_valid.columns:\n",
    "         raise ValueError(f\"Coluna '{comment_column_name_valid}' não encontrada em {valid_file_path}\")\n",
    "\n",
    "    # Tratar possíveis valores nulos na coluna de comentários ANTES de limpar\n",
    "    print(f\"\\nValores nulos na coluna '{comment_column_name_valid}' antes da limpeza na validação: {df_valid[comment_column_name_valid].isnull().sum()}\")\n",
    "    df_valid.dropna(subset=[comment_column_name_valid], inplace=True) # Remover linhas com comentários nulos\n",
    "    print(f\"Shape do dataframe de validação após remover nulos: {df_valid.shape}\")\n",
    "\n",
    "    # Aplicar a função de limpeza à coluna de comentários\n",
    "    df_valid['comment_cleaned'] = df_valid[comment_column_name_valid].apply(clean_text)\n",
    "\n",
    "    print(\"\\nDataFrame de Validação com Comentários Limpos (Primeiras Linhas):\")\n",
    "    print(df_valid.head())\n",
    "\n",
    "    \n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo '{valid_file_path}' não encontrado.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Erro de validação: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao processar {valid_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e21ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame de treino limpo salvo em 'dataset_train_cleaned.parquet'\n"
     ]
    }
   ],
   "source": [
    "# Agora o df_train tem uma coluna 'comment_cleaned' pronta para vetorização/análise\n",
    "# Você pode salvar este DataFrame limpo, talvez em Parquet\n",
    "df_train.to_parquet('dataset_train_cleaned.parquet', index=False)\n",
    "print(\"\\nDataFrame de treino limpo salvo em 'dataset_train_cleaned.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432ca978",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'the pizza was delivered cold and the cheese was n t even fully melted !'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d82fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the pizza was delivered cold and the cheese was n t even fully melted !\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.sub(r'\\s+', ' ', s).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8527649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the pizza was delivered cold and the cheese was n t even fully melted '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[^a-z\\s\\']', '', s) # Mantém letras, espaços e apóstrofos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93fd61a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the pizza was delivered cold and the cheese was n't even fully melted !\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'\\s+n\\s+t\\s+', \" n't \", s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000b1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame de validação limpo salvo em 'dataset_valid_cleaned.parquet'\n"
     ]
    }
   ],
   "source": [
    "# Agora o df_valid tem uma coluna 'comment_cleaned' pronta para predição\n",
    "# Você pode salvar este DataFrame limpo, talvez em Parquet\n",
    "df_valid.to_parquet('dataset_valid_cleaned.parquet', index=False)\n",
    "print(\"\\nDataFrame de validação limpo salvo em 'dataset_valid_cleaned.parquet'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87794be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('dataset_train_inputs.csv')\n",
    "df_valid.to_csv('dataset_valid_inputs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
