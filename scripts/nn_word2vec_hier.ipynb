{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7303965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Importe a classe de clustering hier√°rquico\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# Importe NearestNeighbors para atribuir pontos de teste\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import mlflow\n",
    "# Certifique-se de que a biblioteca static_models est√° instalada ou dispon√≠vel\n",
    "from model2vec import StaticModel # Assumindo que StaticModel √© como no seu c√≥digo\n",
    "# Assumindo que Embeddings √© uma classe base que voc√™ definiu ou importou\n",
    "from langchain.embeddings.base import Embeddings # Assumindo que √© de langchain ou similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d68b0846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/816380000824485392', creation_time=1747411527299, experiment_id='816380000824485392', last_update_time=1747411527299, lifecycle_stage='active', name='Train_Emb_Balanced_Synth-Negative_Sentiment_Analysis_Restaurant', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Ajuste para seu servidor MLflow\n",
    "mlflow.set_experiment(\"Train_Emb_Balanced_Synth-Negative_Sentiment_Analysis_Restaurant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626d13a",
   "metadata": {},
   "source": [
    "INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "328e2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carregar Dados ---\n",
    "# Use um caminho relativo ou absoluto correto para o seu arquivo\n",
    "# Exemplo:\n",
    "# data_path = '../data/dataset_train_with_sentiment_fix_negative_trimmed_similarity.parquet'\n",
    "# df_train = pd.read_parquet(data_path)\n",
    "\n",
    "# Usando o caminho do seu c√≥digo\n",
    "df_train = pd.read_parquet('../data\\dataset_train_trim_synthetic_balanced.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681b8515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando split de treino/teste...\n",
      "Gerando embeddings com Model2Vec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1517d0e84a7941a7b771b54d8ff74bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/30.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521deaffa41e4c4bbc6eaeaa232c29ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/271k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b1c4f1f89547338f6df942bc6c44da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e4a773ff714379865f83c61a2fc9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/684k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando Hierarchical Clustering...\n",
      "Atribuindo clusters do teste usando o vizinho mais pr√≥ximo dos dados de treino (3 clusters)...\n",
      "Treinando modelo supervisionado: LogReg_with_Embeddings+Hierarchical...\n",
      "Avaliando modelo...\n",
      "Accuracy: 0.7007\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.62      0.67        52\n",
      "     Neutral       0.62      0.80      0.70        35\n",
      "    Positive       0.73      0.72      0.72        60\n",
      "\n",
      "    accuracy                           0.70       147\n",
      "   macro avg       0.70      0.71      0.70       147\n",
      "weighted avg       0.71      0.70      0.70       147\n",
      "\n",
      "üèÉ View run LogReg_with_Embeddings+Hierarchical at: http://127.0.0.1:5000/#/experiments/816380000824485392/runs/f0fc65abdcfd4738a46928f558078be8\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/816380000824485392\n",
      "Pipeline conclu√≠do.\n"
     ]
    }
   ],
   "source": [
    "if 'target' not in df_train.columns:\n",
    "    df_train['target'] = df_train['sentiment']\n",
    "\n",
    "X_text = df_train['comment_cleaned']\n",
    "y = df_train['target']\n",
    "\n",
    "# --- Split de Treino e Teste ---\n",
    "print(\"Realizando split de treino/teste...\")\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Sentence Embedding ---\n",
    "class Model2VecEmbeddings(Embeddings):\n",
    "    \"\"\"Wrapper para o Model2Vec como Embeddings do LangChain\"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        # Certifique-se de ter a biblioteca static_models instalada (pip install static-models)\n",
    "        self.model = StaticModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        # Certifique-se de que texts √© uma lista de strings\n",
    "        return self.model.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        # Certifique-se de que text √© uma string\n",
    "        return self.model.encode([text]).tolist()[0]\n",
    "\n",
    "print(\"Gerando embeddings com Model2Vec...\")\n",
    "model_name = \"minishlab/potion-base-8M\"\n",
    "# Instancie a classe e use para gerar embeddings\n",
    "model = Model2VecEmbeddings(model_name)\n",
    "\n",
    "# Converta as Series de texto para listas antes de passar para o modelo\n",
    "X_train_vec = model.embed_documents(X_train_text.tolist())\n",
    "X_test_vec = model.embed_documents(X_test_text.tolist())\n",
    "\n",
    "# Converta as listas de embeddings para arrays numpy para facilitar o processamento\n",
    "X_train_vec = np.array(X_train_vec)\n",
    "X_test_vec = np.array(X_test_vec)\n",
    "\n",
    "\n",
    "# --- Clustering (Hierarchical) ---\n",
    "print(\"Executando Hierarchical Clustering...\")\n",
    "\n",
    "n_clusters = 3 # Manter o mesmo n√∫mero de clusters\n",
    "\n",
    "# Pode escolher diferentes linkages ('ward', 'complete', 'average', 'single')\n",
    "# 'ward' √© comum para embeddings baseados em dist√¢ncia Euclidiana e minimiza a vari√¢ncia dentro dos clusters\n",
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "\n",
    "# Ajustar o modelo nos dados de treino e obter os labels\n",
    "train_clusters = hierarchical_clustering.fit_predict(X_train_vec)\n",
    "\n",
    "# --- Atribuir clusters para os dados de teste ---\n",
    "# Como AgglomerativeClustering n√£o tem 'predict',\n",
    "# atribu√≠mos cada ponto de teste ao cluster do ponto de treino mais pr√≥ximo.\n",
    "\n",
    "print(f\"Atribuindo clusters do teste usando o vizinho mais pr√≥ximo dos dados de treino ({n_clusters} clusters)...\")\n",
    "# Crie um modelo de vizinhos mais pr√≥ximos nos dados de treino\n",
    "nn = NearestNeighbors(n_neighbors=1, metric='euclidean') # Encontre o √∫nico vizinho mais pr√≥ximo\n",
    "nn.fit(X_train_vec)\n",
    "\n",
    "# Para cada ponto no conjunto de teste, encontre o √≠ndice do seu vizinho mais pr√≥ximo no treino\n",
    "distances, indices = nn.kneighbors(X_test_vec) # indices ter√° shape (n_samples_test, 1)\n",
    "\n",
    "# Use os √≠ndices encontrados para obter os r√≥tulos de cluster correspondentes do treino\n",
    "# .flatten() transforma o array de √≠ndices de (n_samples_test, 1) para (n_samples_test,)\n",
    "test_clusters = train_clusters[indices.flatten()]\n",
    "\n",
    "\n",
    "# Adicionar clusters como feature extra\n",
    "# Certifique-se que os arrays de clusters t√™m a forma correta (n_samples, 1)\n",
    "X_train_augmented = np.hstack([X_train_vec, train_clusters.reshape(-1, 1)])\n",
    "X_test_augmented = np.hstack([X_test_vec, test_clusters.reshape(-1, 1)])\n",
    "\n",
    "# --- Modelo Supervisionado (Logistic Regression) ---\n",
    "model_name = \"LogReg_with_Embeddings+Hierarchical\"\n",
    "\n",
    "with mlflow.start_run(run_name=model_name):\n",
    "    print(f\"Treinando modelo supervisionado: {model_name}...\")\n",
    "    # Ajuste os par√¢metros da Regress√£o Log√≠stica conforme necess√°rio\n",
    "    clf = LogisticRegression(C=10, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train_augmented, y_train)\n",
    "\n",
    "    print(\"Avaliando modelo...\")\n",
    "    y_pred = clf.predict(X_test_augmented)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # Gere o relat√≥rio de classifica√ß√£o como um dicion√°rio para MLflow\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    # Gere o relat√≥rio de classifica√ß√£o para exibi√ß√£o no console\n",
    "    report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report_str)\n",
    "\n",
    "    # --- Log MLflow ---\n",
    "    # N√£o use autolog() se voc√™ est√° registrando par√¢metros e m√©tricas manualmente\n",
    "    # mlflow.autolog() # Remova ou comente esta linha se registrar manualmente\n",
    "\n",
    "    mlflow.log_param(\"embedding_model\", model_name) # O nome do modelo de embedding\n",
    "    mlflow.log_param(\"classifier\", type(clf).__name__) # Nome da classe do classificador\n",
    "    mlflow.log_param(\"C\", clf.C)\n",
    "    mlflow.log_param(\"penalty\", clf.penalty)\n",
    "    mlflow.log_param(\"solver\", clf.solver)\n",
    "    mlflow.log_param(\"max_iter\", clf.max_iter)\n",
    "    # Logar os par√¢metros do clustering hier√°rquico\n",
    "    mlflow.log_param(\"clustering_method\", \"Hierarchical Clustering\")\n",
    "    mlflow.log_param(\"hierarchical_clusters\", n_clusters)\n",
    "    mlflow.log_param(\"hierarchical_linkage\", hierarchical_clustering.linkage)\n",
    "    mlflow.log_param(\"test_cluster_assignment\", \"NearestNeighbor\") # M√©todo usado para teste\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_dict(report, \"classification_report.json\")\n",
    "\n",
    "print(\"Pipeline conclu√≠do.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
