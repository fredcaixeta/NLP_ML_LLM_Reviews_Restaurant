{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d485ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from model2vec import StaticModel\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5d8446c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model2vec.hf_utils:Folder does not exist locally, attempting to use huggingface hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando embeddings com Model2Vec...\n"
     ]
    }
   ],
   "source": [
    "# --- Sentence Embedding ---\n",
    "class Model2VecEmbeddings(Embeddings):\n",
    "        \"\"\"Wrapper para o Model2Vec como Embeddings do LangChain\"\"\"\n",
    "        def __init__(self, model_name: str):\n",
    "            self.model = StaticModel.from_pretrained(model_name)\n",
    "\n",
    "        def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "            return self.model.encode(texts).tolist()\n",
    "        \n",
    "        def embed_query(self, text: str) -> List[float]:\n",
    "            return self.model.encode([text]).tolist()[0]\n",
    "        \n",
    "print(\"Gerando embeddings com Model2Vec...\")\n",
    "model_name = \"minishlab/potion-base-2M\"\n",
    "emb_model_name = Model2VecEmbeddings(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ecdab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/164704175141499300', creation_time=1747257156553, experiment_id='164704175141499300', last_update_time=1747257156553, lifecycle_stage='active', name='Valid_Emb_Trimmed_Fix-Negative_Sentiment_Analysis_Restaurant', tags={}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Ajuste para seu servidor MLflow\n",
    "# Experimento MLflow\n",
    "mlflow.set_experiment(\"Valid_Emb_Trimmed_Fix-Negative_Sentiment_Analysis_Restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2d6768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentValidatorEmbeddings:\n",
    "    def __init__(self, parquet_path, embedding_model_name = \"minishlab/potion-base-2M\"):\n",
    "        self.embedding_model = Model2VecEmbeddings(embedding_model_name)\n",
    "        self.parquet_path = parquet_path\n",
    "        self.label_mapping = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "        self.inverse_mapping = {v: k for k, v in self.label_mapping.items()}\n",
    "        \n",
    "    def load_model_and_components(self, model_name):\n",
    "        \"\"\"Carrega o modelo e extrai o vetorizador corretamente\"\"\"\n",
    "        try:\n",
    "            model_uri = f\"models:/sentiment_{model_name}/latest\"\n",
    "            \n",
    "            sklearn_model = mlflow.sklearn.load_model(model_uri)\n",
    "            return sklearn_model\n",
    "        \n",
    "        except Exception as e:\n",
    "            model_uri = f\"models:/{model_name}/latest\"\n",
    "            \n",
    "            sklearn_model = mlflow.sklearn.load_model(model_uri)\n",
    "            return sklearn_model\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            df = pd.read_parquet(self.parquet_path)\n",
    "            df = df[df['sentiment'].isin(self.label_mapping.keys())]\n",
    "            df = df.dropna(subset=['comment_cleaned', 'sentiment'])\n",
    "            if len(df) == 0:\n",
    "                raise ValueError(\"Nenhum dado v√°lido ap√≥s filtragem\")\n",
    "            return df['comment_cleaned'].values, df['sentiment'].values\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao carregar dados: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"Valida usando embeddings + KMeans + modelo supervisionado\"\"\"\n",
    "        try:\n",
    "            with mlflow.start_run(run_name=\"Valid_Emb_KMeans\"):\n",
    "                X_val_raw, y_val = self.load_data()\n",
    "                logger.info(f\"Valida√ß√£o com {len(X_val_raw)} amostras\")\n",
    "\n",
    "                # 1. Embedding\n",
    "                X_embed = self.embedding_model.embed_documents(X_val_raw)\n",
    "\n",
    "                # 2. Baixar artifacts: kmeans e modelo\n",
    "                model = self.load_model_and_components(model_name=\"LogReg_Emb_KMeans\")\n",
    "                \n",
    "                # 3. Clustering\n",
    "                cluster_features = model.predict(X_embed).reshape(-1, 1)\n",
    "                X_val_aug = np.hstack([X_embed, cluster_features])\n",
    "\n",
    "                # 4. Infer√™ncia\n",
    "                y_pred = model.predict(X_val_aug)\n",
    "                y_pred_text = [self.inverse_mapping.get(int(y), \"Neutral\") for y in y_pred]\n",
    "\n",
    "                # 5. M√©tricas\n",
    "                self._log_metrics(y_val, y_pred_text)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro na valida√ß√£o: {str(e)}\")\n",
    "\n",
    "    def _log_metrics(self, y_true, y_pred):\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"val_accuracy\": acc,\n",
    "            \"val_f1_weighted\": f1\n",
    "        })\n",
    "\n",
    "        for cls in ['Negative', 'Neutral', 'Positive']:\n",
    "            if cls in report:\n",
    "                mlflow.log_metrics({\n",
    "                    f\"val_precision_{cls.lower()}\": report[cls]['precision'],\n",
    "                    f\"val_recall_{cls.lower()}\": report[cls]['recall'],\n",
    "                    f\"val_f1_{cls.lower()}\": report[cls]['f1-score'],\n",
    "                    f\"val_support_{cls.lower()}\": report[cls]['support']\n",
    "                })\n",
    "\n",
    "        self._plot_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    def _plot_confusion_matrix(self, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=['Negative', 'Neutral', 'Positive'])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Negative', 'Neutral', 'Positive'],\n",
    "                    yticklabels=['Negative', 'Neutral', 'Positive'])\n",
    "        plt.title('Matriz de Confus√£o - Valida√ß√£o')\n",
    "        plt.ylabel('Verdadeiro')\n",
    "        plt.xlabel('Previsto')\n",
    "        cm_path = \"confusion_matrix_val.png\"\n",
    "        plt.savefig(cm_path)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1521bfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model2vec.hf_utils:Folder does not exist locally, attempting to use huggingface hub.\n",
      "INFO:__main__:Valida√ß√£o com 195 amostras\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d14a9b4dc3346dfb3829ac4343da056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Erro na valida√ß√£o: X has 64 features, but LogisticRegression is expecting 65 features as input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Valid_Emb_KMeans at: http://127.0.0.1:5000/#/experiments/164704175141499300/runs/8194748c4c6f4e12ae7611ce9214be99\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/164704175141499300\n"
     ]
    }
   ],
   "source": [
    "validator = SentimentValidatorEmbeddings(\n",
    "    parquet_path=\"../data\\dataset_valid_with_sentiment_fix_negative_trimmed_similarity.parquet\",\n",
    ")\n",
    "\n",
    "validator.validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
