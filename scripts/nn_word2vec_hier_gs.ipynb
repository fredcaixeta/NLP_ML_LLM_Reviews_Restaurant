{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a183945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Importe a classe de clustering hier√°rquico\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# Importe NearestNeighbors para atribuir pontos de teste\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import mlflow\n",
    "# Certifique-se de que a biblioteca static_models est√° instalada ou dispon√≠vel\n",
    "from model2vec import StaticModel # Assumindo que StaticModel √© como no seu c√≥digo\n",
    "# Assumindo que Embeddings √© uma classe base que voc√™ definiu ou importou\n",
    "from langchain.embeddings.base import Embeddings # Assumindo que √© de langchain ou similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6567e6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/816380000824485392', creation_time=1747411527299, experiment_id='816380000824485392', last_update_time=1747411527299, lifecycle_stage='active', name='Train_Emb_Balanced_Synth-Negative_Sentiment_Analysis_Restaurant', tags={}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Ajuste para seu servidor MLflow\n",
    "mlflow.set_experiment(\"Train_Emb_Balanced_Synth-Negative_Sentiment_Analysis_Restaurant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad99d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sentence Embedding ---\n",
    "class Model2VecEmbeddings(Embeddings):\n",
    "    \"\"\"Wrapper para o Model2Vec como Embeddings do LangChain\"\"\"\n",
    "    def __init__(self, model_name: str):\n",
    "        # Certifique-se de ter a biblioteca static_models instalada (pip install static-models)\n",
    "        self.model = StaticModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        # Certifique-se de que texts √© uma lista de strings\n",
    "        return self.model.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        # Certifique-se de que text √© uma string\n",
    "        return self.model.encode([text]).tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d5e70",
   "metadata": {},
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30637998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizando split de treino/teste...\n"
     ]
    }
   ],
   "source": [
    "# Usando o caminho do seu c√≥digo\n",
    "df_train = pd.read_parquet('../data\\dataset_train_trim_synthetic_balanced.parquet')\n",
    "\n",
    "if 'target' not in df_train.columns:\n",
    "    df_train['target'] = df_train['sentiment']\n",
    "\n",
    "X_text = df_train['comment_cleaned']\n",
    "y = df_train['target']\n",
    "\n",
    "# --- Split de Treino e Teste ---\n",
    "print(\"Realizando split de treino/teste...\")\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08e2ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing embedding model: minishlab/potion-base-8M\n",
      "\n",
      "Testing clustering with 3 clusters and ward linkage...\n",
      "Best recall for this config: 0.7415458937198066\n",
      "New best model! Test recall: 0.7308\n",
      "\n",
      "Testing clustering with 3 clusters and complete linkage...\n",
      "Best recall for this config: 0.707936507936508\n",
      "\n",
      "Testing clustering with 3 clusters and average linkage...\n",
      "Best recall for this config: 0.7222222222222222\n",
      "\n",
      "Logging best model to MLflow...\n",
      "Best parameters:\n",
      "{'embedding_model': 'minishlab/potion-base-8M', 'n_clusters': 3, 'linkage': 'ward', 'lr_params': {'C': 0.1, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuedj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\fuedj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\fuedj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/05/16 13:32:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test recall for negative class: 0.0000\n",
      "Best model logged to MLflow\n",
      "üèÉ View run Best_LogReg_Embeddings_Cluster at: http://127.0.0.1:5000/#/experiments/816380000824485392/runs/cee92191f80b484e9a902b26330affc7\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/816380000824485392\n",
      "Grid search complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "ALL_LABELS = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# --- Fun√ß√£o Scorer Customizada para Recall da Classe 'Negative' ---\n",
    "def recall_negative_scorer_func(y_true, y_pred):\n",
    "    # Calcula o recall para *todas* as classes presentes, retornando um array.\n",
    "    # Usamos `labels=ALL_LABELS` para garantir a ordem consistente\n",
    "    # e `zero_division=0` para que folds sem a classe 'Negative' em y_true resultem em 0.\n",
    "    per_class_recall = recall_score(y_true, y_pred, average=None, labels=ALL_LABELS, zero_division=0)\n",
    "\n",
    "    # Encontra o √≠ndice da classe 'Negative' na lista ALL_LABELS\n",
    "    try:\n",
    "        neg_index = ALL_LABELS.index('Negative')\n",
    "        # Retorna o recall correspondente a esse √≠ndice\n",
    "        return per_class_recall[neg_index]\n",
    "    except ValueError:\n",
    "        # Isso s√≥ deve acontecer se 'Negative' n√£o estiver em ALL_LABELS - verifique sua lista!\n",
    "        print(f\"Erro: 'Negative' n√£o encontrado na lista ALL_LABELS: {ALL_LABELS}\")\n",
    "        return np.nan # Retorna NaN para indicar um problema de configura√ß√£o\n",
    "\n",
    "# --- Defina nosso scorer usando a fun√ß√£o customizada ---\n",
    "# make_scorer agora usa a fun√ß√£o que retorna um √∫nico valor (o recall da classe 'Negative')\n",
    "scorer = make_scorer(recall_negative_scorer_func)\n",
    "\n",
    "# --- Embedding Models Grid ---\n",
    "embedding_models = {\n",
    "    \"minishlab/potion-base-8M\": Model2VecEmbeddings(\"minishlab/potion-base-8M\")\n",
    "}\n",
    "\n",
    "# --- Logistic Regression Hyperparameters Grid ---\n",
    "lr_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],  # These solvers support both L1 and L2\n",
    "    'max_iter': [500, 1000]\n",
    "}\n",
    "\n",
    "# --- Clustering Parameters Grid ---\n",
    "clustering_params = {\n",
    "    'n_clusters': [3],\n",
    "    'linkage': ['ward', 'complete', 'average']\n",
    "}\n",
    "\n",
    "best_recall = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "# Main grid search loop\n",
    "for emb_name, emb_model in embedding_models.items():\n",
    "    print(f\"\\nTesting embedding model: {emb_name}\")\n",
    "    \n",
    "    # Generate embeddings\n",
    "    X_train_vec = np.array(emb_model.embed_documents(X_train_text.tolist()))\n",
    "    X_test_vec = np.array(emb_model.embed_documents(X_test_text.tolist()))\n",
    "    \n",
    "    for n_clusters in clustering_params['n_clusters']:\n",
    "        for linkage in clustering_params['linkage']:\n",
    "            print(f\"\\nTesting clustering with {n_clusters} clusters and {linkage} linkage...\")\n",
    "            \n",
    "            # Hierarchical clustering\n",
    "            hc = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
    "            train_clusters = hc.fit_predict(X_train_vec)\n",
    "            \n",
    "            # Assign test clusters using nearest neighbor\n",
    "            nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "            nn.fit(X_train_vec)\n",
    "            _, indices = nn.kneighbors(X_test_vec)\n",
    "            test_clusters = train_clusters[indices.flatten()]\n",
    "            \n",
    "            # Augment features\n",
    "            X_train_aug = np.hstack([X_train_vec, train_clusters.reshape(-1, 1)])\n",
    "            X_test_aug = np.hstack([X_test_vec, test_clusters.reshape(-1, 1)])\n",
    "            \n",
    "            # Logistic Regression grid search\n",
    "            lr = LogisticRegression(random_state=42)\n",
    "            grid = GridSearchCV(lr, lr_params, scoring=scorer, cv=3, n_jobs=-1)\n",
    "            grid.fit(X_train_aug, y_train)\n",
    "            \n",
    "            # Get best model from this iteration\n",
    "            current_recall = grid.best_score_\n",
    "            print(f\"Best recall for this config: {current_recall}\")\n",
    "            \n",
    "            # Track best overall model\n",
    "            if current_recall > best_recall:\n",
    "                best_recall = current_recall\n",
    "                best_params = {\n",
    "                    'embedding_model': emb_name,\n",
    "                    'n_clusters': n_clusters,\n",
    "                    'linkage': linkage,\n",
    "                    'lr_params': grid.best_params_\n",
    "                }\n",
    "                best_model = grid.best_estimator_\n",
    "                \n",
    "                # Evaluate on test set (using the full y_test)\n",
    "                # Evaluate on test set (using the full y_test)\n",
    "                y_pred = best_model.predict(X_test_aug)\n",
    "\n",
    "                # Calcule o recall para cada classe e selecione o da classe 'Negative'\n",
    "                # Certifique-se de que ALL_LABELS est√° definido no topo do seu script\n",
    "                per_class_recall_test = recall_score(y_test, y_pred, average=None, labels=ALL_LABELS)\n",
    "                neg_index = ALL_LABELS.index('Negative')\n",
    "                test_recall = per_class_recall_test[neg_index] # Seleciona o recall da classe 'Negative'\n",
    "\n",
    "                print(f\"New best model! Test recall: {test_recall:.4f}\")\n",
    "\n",
    "# --- Log best model to MLflow ---\n",
    "with mlflow.start_run(run_name=\"Best_LogReg_Embeddings_Cluster\"):\n",
    "    print(\"\\nLogging best model to MLflow...\")\n",
    "    print(\"Best parameters:\")\n",
    "    print(best_params)\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        'embedding_model': best_params['embedding_model'],\n",
    "        'n_clusters': best_params['n_clusters'],\n",
    "        'linkage': best_params['linkage'],\n",
    "        'lr_C': best_params['lr_params']['C'],\n",
    "        'lr_penalty': best_params['lr_params']['penalty'],\n",
    "        'lr_solver': best_params['lr_params']['solver'],\n",
    "        'lr_max_iter': best_params['lr_params']['max_iter']\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    y_pred = best_model.predict(X_test_aug)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calcule o recall para cada classe e selecione o da classe 'Negative'\n",
    "    # Certifique-se de que ALL_LABELS est√° definido no topo do seu script\n",
    "    per_class_recall_mlflow = recall_score(y_test, y_pred, average=None, labels=ALL_LABELS)\n",
    "    neg_index = ALL_LABELS.index('Negative')\n",
    "    neg_recall = per_class_recall_mlflow[neg_index] # Seleciona o recall da classe 'Negative'\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    mlflow.log_metrics({\n",
    "        'accuracy': acc,\n",
    "        'recall_negative': neg_recall\n",
    "    })\n",
    "    mlflow.log_dict(report, \"classification_report.json\")\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(best_model, \"model\")\n",
    "    \n",
    "    print(f\"Final test recall for negative class: {neg_recall:.4f}\")\n",
    "    print(\"Best model logged to MLflow\")\n",
    "\n",
    "print(\"Grid search complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bcdd998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Debugging data for minishlab/potion-base-8M, n_clusters=3, linkage=average ---\n",
      "Shape of X_train_aug: (586, 257)\n",
      "Are there NaNs in X_train_aug? False\n",
      "Are there Infs in X_train_aug? False\n",
      "Min value in X_train_aug: -0.4777367413043976\n",
      "Max value in X_train_aug: 2.0\n",
      "Mean value in X_train_aug: -0.00026017618687688494\n",
      "Shape of y_train: (586,)\n",
      "y_train value counts: (array(['Negative', 'Neutral', 'Positive'], dtype=object), array([209, 139, 238], dtype=int64))\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dentro do loop de clustering, AP√ìS gerar X_train_aug e y_train\n",
    "if emb_name == \"minishlab/potion-base-8M\":\n",
    "    print(f\"--- Debugging data for {emb_name}, n_clusters={n_clusters}, linkage={linkage} ---\")\n",
    "    print(\"Shape of X_train_aug:\", X_train_aug.shape)\n",
    "    print(\"Are there NaNs in X_train_aug?\", np.isnan(X_train_aug).any())\n",
    "    print(\"Are there Infs in X_train_aug?\", np.isinf(X_train_aug).any())\n",
    "    print(\"Min value in X_train_aug:\", np.nanmin(X_train_aug) if np.isnan(X_train_aug).any() else X_train_aug.min())\n",
    "    print(\"Max value in X_train_aug:\", np.nanmax(X_train_aug) if np.isnan(X_train_aug).any() else X_train_aug.max())\n",
    "    print(\"Mean value in X_train_aug:\", np.nanmean(X_train_aug) if np.isnan(X_train_aug).any() else X_train_aug.mean())\n",
    "    print(\"Shape of y_train:\", y_train.shape)\n",
    "    \n",
    "    #print(\"Are there NaNs in y_train?\", np.isnan(y_train)) # Deve ser False para labels\n",
    "    print(\"y_train value counts:\", np.unique(y_train, return_counts=True))\n",
    "    print(\"-----------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
