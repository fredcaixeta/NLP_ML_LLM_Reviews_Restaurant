{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2061db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o de logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SentimentValidator:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = None\n",
    "        self.label_mapping = {'Negative': 0, 'Neutral': 1, 'Positive': 2}\n",
    "        self.inverse_mapping = {v: k for k, v in self.label_mapping.items()}\n",
    "\n",
    "    def load_data(self, parquet_path):\n",
    "        \"\"\"Carrega e transforma os dados de valida√ß√£o\"\"\"\n",
    "        try:\n",
    "            df = pd.read_parquet(parquet_path)\n",
    "            \n",
    "            # Verifica√ß√£o de colunas essenciais\n",
    "            if not all(col in df.columns for col in ['comment_cleaned', 'sentiment']):\n",
    "                raise ValueError(\"Colunas 'comment_cleaned' ou 'sentiment' n√£o encontradas\")\n",
    "            \n",
    "            # Filtragem e limpeza\n",
    "            df = df[df['sentiment'].isin(self.label_mapping.keys())]\n",
    "            df = df.dropna(subset=['comment_cleaned', 'sentiment'])\n",
    "            \n",
    "            if len(df) == 0:\n",
    "                raise ValueError(\"Nenhum dado v√°lido ap√≥s filtragem\")\n",
    "                \n",
    "            return df['comment_cleaned'].values, df['sentiment'].values\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao carregar dados: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_model_and_components(self, model_name):\n",
    "        \"\"\"Carrega o modelo e extrai o vetorizador corretamente\"\"\"\n",
    "        try:\n",
    "            model_uri = f\"models:/sentiment_{model_name}/latest\"\n",
    "            \n",
    "            sklearn_model = mlflow.sklearn.load_model(model_uri)\n",
    "            return sklearn_model\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao carregar modelo {model_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def transform_data(self, X):\n",
    "        \"\"\"Transforma os dados conforme o pipeline de treinamento\"\"\"\n",
    "        if self.vectorizer is None:\n",
    "            logger.warning(\"Vetorizador n√£o encontrado, criando novo como fallback\")\n",
    "            self.vectorizer = TfidfVectorizer(max_features=5000)\n",
    "            \n",
    "            # Apenas fit se for um novo vetorizador (evitar data leakage)\n",
    "            self.vectorizer.fit(X)\n",
    "        \n",
    "        return self.vectorizer.transform(X)\n",
    "\n",
    "    def validate(self, model_name=\"randomforest\", parquet_path=\"../data/dataset_valid_with_sentiment.parquet\"):\n",
    "        \"\"\"Executa a valida√ß√£o completa\"\"\"\n",
    "        try:\n",
    "            with mlflow.start_run(run_name=f\"Validation_{model_name}\"):\n",
    "                # 1. Carregar dados\n",
    "                X_val, y_val_true = self.load_data(parquet_path)\n",
    "                logger.info(f\"Dados carregados: {len(X_val)} amostras\")\n",
    "                \n",
    "                # 2. Carregar modelo e componentes\n",
    "                model = self.load_model_and_components(model_name)\n",
    "                \n",
    "                # 3. Fazer previs√µes diretamente (o modelo j√° inclui o pipeline completo)\n",
    "                y_val_pred = model.predict(X_val)\n",
    "                \n",
    "                # 4. Converter labels num√©ricos para texto se necess√°rio\n",
    "                if all(isinstance(x, (int, float, np.integer)) for x in y_val_pred):\n",
    "                    y_val_pred = [self.inverse_mapping.get(int(x), 'Neutral') for x in y_val_pred]\n",
    "                \n",
    "                # 5. Calcular m√©tricas\n",
    "                self._log_metrics(y_val_true, y_val_pred, model_name)\n",
    "                \n",
    "                return True\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Falha na valida√ß√£o: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _log_metrics(self, y_true, y_pred, model_name):\n",
    "        \"\"\"Calcula e registra m√©tricas no MLflow\"\"\"\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        \n",
    "        # Log b√°sico\n",
    "        mlflow.log_metrics({\n",
    "            \"val_accuracy\": accuracy,\n",
    "            \"val_f1_weighted\": f1\n",
    "        })\n",
    "        \n",
    "        # Log por classe\n",
    "        for cls in ['Negative', 'Neutral', 'Positive']:\n",
    "            if cls in report:\n",
    "                mlflow.log_metrics({\n",
    "                    f\"val_precision_{cls.lower()}\": report[cls]['precision'],\n",
    "                    f\"val_recall_{cls.lower()}\": report[cls]['recall'],\n",
    "                    f\"val_f1_{cls.lower()}\": report[cls]['f1-score'],\n",
    "                    f\"val_support_{cls.lower()}\": report[cls]['support']\n",
    "                })\n",
    "        \n",
    "        # Matriz de confus√£o\n",
    "        self._plot_confusion_matrix(y_true, y_pred, model_name)\n",
    "        \n",
    "        logger.info(f\"\\nModelo: {model_name}\")\n",
    "        logger.info(f\"Acur√°cia: {accuracy:.4f}\")\n",
    "        logger.info(f\"F1-Score: {f1:.4f}\")\n",
    "        logger.info(\"\\nRelat√≥rio de Classifica√ß√£o:\")\n",
    "        logger.info(classification_report(y_true, y_pred))\n",
    "\n",
    "    def _plot_confusion_matrix(self, y_true, y_pred, model_name):\n",
    "        \"\"\"Gera e salva a matriz de confus√£o\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=['Negative', 'Neutral', 'Positive'])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Negative', 'Neutral', 'Positive'],\n",
    "                    yticklabels=['Negative', 'Neutral', 'Positive'])\n",
    "        plt.title(f'Matriz de Confus√£o - {model_name}')\n",
    "        plt.ylabel('Verdadeiro')\n",
    "        plt.xlabel('Previsto')\n",
    "        \n",
    "        cm_path = f\"confusion_matrix_{model_name}.png\"\n",
    "        plt.savefig(cm_path)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a87b0a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Iniciando valida√ß√£o para randomforest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dados carregados: 199 amostras\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e61cc522234ffcbe121bc051368dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Modelo: randomforest\n",
      "INFO:__main__:Acur√°cia: 0.6985\n",
      "INFO:__main__:F1-Score: 0.6437\n",
      "INFO:__main__:\n",
      "Relat√≥rio de Classifica√ß√£o:\n",
      "INFO:__main__:              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.42      0.53        50\n",
      "     Neutral       0.33      0.04      0.07        25\n",
      "    Positive       0.70      0.94      0.81       124\n",
      "\n",
      "    accuracy                           0.70       199\n",
      "   macro avg       0.58      0.47      0.47       199\n",
      "weighted avg       0.66      0.70      0.64       199\n",
      "\n",
      "INFO:__main__:Valida√ß√£o de randomforest conclu√≠da com sucesso!\n",
      "INFO:__main__:\n",
      "Iniciando valida√ß√£o para logisticregression...\n",
      "INFO:__main__:Dados carregados: 199 amostras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Validation_randomforest at: http://127.0.0.1:5000/#/experiments/768184713491958936/runs/ed4f45879c4548068e78f3a4b1fbe18a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/768184713491958936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6cac2713fa43528a490628353aeb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "Modelo: logisticregression\n",
      "INFO:__main__:Acur√°cia: 0.6884\n",
      "INFO:__main__:F1-Score: 0.6068\n",
      "INFO:__main__:\n",
      "Relat√≥rio de Classifica√ß√£o:\n",
      "INFO:__main__:              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.92      0.24      0.38        50\n",
      "     Neutral       0.50      0.04      0.07        25\n",
      "    Positive       0.67      1.00      0.81       124\n",
      "\n",
      "    accuracy                           0.69       199\n",
      "   macro avg       0.70      0.43      0.42       199\n",
      "weighted avg       0.71      0.69      0.61       199\n",
      "\n",
      "INFO:__main__:Valida√ß√£o de logisticregression conclu√≠da com sucesso!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Validation_logisticregression at: http://127.0.0.1:5000/#/experiments/768184713491958936/runs/755fe2a5a3174e619d022fa7a5831967\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/768184713491958936\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"Restaurant_Sentiment_Validation\")\n",
    "\n",
    "validator = SentimentValidator()\n",
    "\n",
    "# Lista de modelos para validar\n",
    "models_to_validate = ['randomforest', 'logisticregression']\n",
    "\n",
    "for model_name in models_to_validate:\n",
    "    logger.info(f\"\\nIniciando valida√ß√£o para {model_name}...\")\n",
    "    success = validator.validate(model_name)\n",
    "    \n",
    "    if success:\n",
    "        logger.info(f\"Valida√ß√£o de {model_name} conclu√≠da com sucesso!\")\n",
    "    else:\n",
    "        logger.info(f\"Valida√ß√£o de {model_name} falhou.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
