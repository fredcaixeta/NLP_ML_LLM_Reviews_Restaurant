{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 22:10:05 INFO mlflow.tracking.fluent: Experiment with name 'Restaurant_Reviews_Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/105878113738556386', creation_time=1747185005345, experiment_id='105878113738556386', last_update_time=1747185005345, lifecycle_stage='active', name='Restaurant_Reviews_Classification', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Configura√ß√£o do MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")  # Ajuste para seu servidor MLflow\n",
    "mlflow.set_experiment(\"Sentiment Analysis Restaurant Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b772c218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 22:57:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "Registered model 'sentiment_randomforest' already exists. Creating a new version of this model...\n",
      "2025/05/13 22:57:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: sentiment_randomforest, version 2\n",
      "Created version '2' of model 'sentiment_randomforest'.\n",
      "2025/05/13 22:57:13 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.7099\n",
      "üèÉ View run RandomForest at: http://127.0.0.1:5000/#/experiments/744206330945824458/runs/a54e15eda2da4aa59cd24f86d9084598\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/744206330945824458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 22:57:21 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n",
      "C:\\Users\\fuedj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\fuedj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\fuedj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025/05/13 22:57:21 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/05/13 22:57:21 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n",
      "Registered model 'sentiment_logisticregression' already exists. Creating a new version of this model...\n",
      "2025/05/13 22:57:27 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: sentiment_logisticregression, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.6947\n",
      "üèÉ View run LogisticRegression at: http://127.0.0.1:5000/#/experiments/744206330945824458/runs/be478411bc5f41b0b07fb0a35285914a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/744206330945824458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'sentiment_logisticregression'.\n"
     ]
    }
   ],
   "source": [
    "# Assume df_train and df_valid with 'comment_cleaned' and 'target' columns are ready\n",
    "# For demonstration, let's create dummy data if they don't exist\n",
    "try:\n",
    "    df_train = pd.read_parquet('data/dataset_train_with_sentiment.parquet') # Or load from CSV\n",
    "    df_valid = pd.read_parquet('data/dataset_valid_with_sentiment.parquet') # Or load from CSV\n",
    "    # Ensure 'target' column exists in df_train (added by LLM)\n",
    "    if 'target' not in df_train.columns:\n",
    "        # Duplicando 'coluna_original' para 'nova_coluna'\n",
    "        df_train['target'] = df_train['sentiment']\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivos limpos n√£o encontrados. Criando DataFrames de exemplo para demonstra√ß√£o.\")\n",
    "    # Create dummy dataframes for demonstration if files aren't found\n",
    "    data_train = {'comment_cleaned': ['√≥timo lugar recomendo', 'comida fria e atendimento ruim', 'ambiente agrad√°vel pre√ßo justo', 'demorou muito para chegar', 'tudo perfeito voltarei'],\n",
    "                  'target': ['Positivo', 'Negativo', 'Positivo', 'Negativo', 'Positivo']}\n",
    "    df_train = pd.DataFrame(data_train)\n",
    "\n",
    "    data_valid = {'comment_cleaned': ['servi√ßo excelente', 'conta veio errada', 'local barulhento', 'pizza saborosa']}\n",
    "    df_valid = pd.DataFrame(data_valid)\n",
    "    print(\"DataFrames de exemplo criados.\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_train['comment_cleaned']\n",
    "y = df_train['target']\n",
    "\n",
    "# --- MLflow Setup ---\n",
    "\n",
    "# --- Preparar dados para treinamento e avalia√ß√£o (split interno) ---\n",
    "# Dividir a base de treino em treino e valida√ß√£o PARA ACOMPANHAMENTO DO MLflow\n",
    "# Isso permite avaliar o modelo em dados que ele n√£o viu durante o treinamento deste run espec√≠fico\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y) # Usar stratify para manter propor√ß√£o das classes\n",
    "\n",
    "\n",
    "# Modelos para testar\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Vetorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    \n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        #Pipeline\n",
    "        pipeline = Pipeline([\n",
    "                ('tfidf', vectorizer),\n",
    "                ('clf', model)\n",
    "            ])\n",
    "        # Treino\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Avalia√ß√£o\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        mlflow.autolog()\n",
    "        \n",
    "        print(f\"{model_name} - Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular m√©tricas\n",
    "accuracy = accuracy_score(y_train_split, y_eval_split)\n",
    "precision = precision_score(y_train_split, y_eval_split, average='weighted', zero_division=0) # Use weighted/macro/micro dependendo da distribui√ß√£o das classes\n",
    "recall = recall_score(y_train_split, y_eval_split, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_train_split, y_eval_split, average='weighted', zero_division=0)\n",
    "\n",
    "# Logar as m√©tricas\n",
    "mlflow.log_metric(\"eval_accuracy\", accuracy)\n",
    "mlflow.log_metric(\"eval_precision\", precision)\n",
    "mlflow.log_metric(\"eval_recall\", recall)\n",
    "mlflow.log_metric(\"eval_f1_score\", f1)\n",
    "\n",
    "print(f\"\\nM√©tricas no conjunto de avalia√ß√£o interno:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_eval_split, y_pred_eval, zero_division=0))\n",
    "\n",
    "    # TfidfVectorizer.\n",
    "    # # --- Logar o Modelo (a Pipeline completa) ---\n",
    "    # # Isso salva o vetorizador e o classificador juntos\n",
    "    # mlflow.sklearn.log_model(pipeline, \"sentiment_model_pipeline\")\n",
    "\n",
    "    # print(\"\\nModelo (Pipeline) logado no MLflow.\")\n",
    "    # print(f\"MLflow Run ID: {mlflow.active_run().info.run_id}\")\n",
    "    # print(\"Run finalizado.\")\n",
    "\n",
    "# --- Pr√≥ximos Passos ---\n",
    "# Ap√≥s rodar o script v√°rias vezes com diferentes par√¢metros,\n",
    "# voc√™ pode visualizar os resultados usando a UI do MLflow.\n",
    "# No seu terminal, navegue at√© o diret√≥rio onde voc√™ rodou este script\n",
    "# e execute: mlflow ui\n",
    "# Isso abrir√° uma interface web onde voc√™ pode comparar os runs pelas m√©tricas e par√¢metros.\n",
    "\n",
    "# Depois de escolher o melhor conjunto de par√¢metros, voc√™ treinaria a pipeline FINAL\n",
    "# Usando a base de treino COMPLETA (X_train_cleaned, y_train) e logaria/registraria\n",
    "# esse modelo final de forma distinta, se necess√°rio.\n",
    "# Exemplo (Fora do run de experimenta√ß√£o):\n",
    "# final_pipeline = Pipeline([...com_os_melhores_parametros...])\n",
    "# final_pipeline.fit(X_train_cleaned, y_train)\n",
    "# joblib.dump(final_pipeline, 'final_sentiment_pipeline.pkl') # Salvar para usar na predi√ß√£o da valida√ß√£o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
